{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpiVmEKnoINWXbkbSF2aB3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomohitom/Tennis_Game_Analysis/blob/master/pytorch_iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE4MJ4p8DAdG",
        "outputId": "232d4960-00c9-4290-e155-0d002093166a"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.nn as nn\r\n",
        "from torch.autograd import Variable\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class Model(nn.Module):\r\n",
        "  def __init__(self, input_dim):\r\n",
        "    super(Model, self).__init__()\r\n",
        "    self.layer1 = nn.Linear(input_dim, 50)\r\n",
        "    self.layer2 = nn.Linear(50,50)\r\n",
        "    self.layer3 = nn.Linear(50, 3)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = F.relu(self.layer1(x))\r\n",
        "    x = F.relu(self.layer2(x))\r\n",
        "    x = F.softmax(self.layer3(x), dim=1)\r\n",
        "    return x\r\n",
        "\r\n",
        "df = pd.read_csv('sample_data/iris.csv')\r\n",
        "df = df.dropna(how = \"any\", axis = 0)\r\n",
        "\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "le = LabelEncoder()\r\n",
        "le.fit(df['種類'])\r\n",
        "\r\n",
        "X = df.loc[:, :'花弁幅']\r\n",
        "y = le.transform(df['種類'])\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\r\n",
        "\r\n",
        "X_train = Variable(torch.from_numpy(X_train.to_numpy())).float()\r\n",
        "y_train = Variable(torch.from_numpy(y_train))\r\n",
        "X_test = Variable(torch.from_numpy(X_test.to_numpy())).float()\r\n",
        "y_test = Variable(torch.from_numpy(y_test))\r\n",
        "\r\n",
        "model = Model(X_train.shape[1])\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\r\n",
        "loss_fn = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "import tqdm\r\n",
        "\r\n",
        "EPOCHS = 100\r\n",
        "loss_list = np.zeros((EPOCHS, ))\r\n",
        "accuracy_list = np.zeros((EPOCHS, ))\r\n",
        "\r\n",
        "for epoch in tqdm.trange(EPOCHS):\r\n",
        "  y_pred = model(X_train)\r\n",
        "  loss = loss_fn(y_pred, y_train)\r\n",
        "  print(loss.item())\r\n",
        "  loss_list[epoch] = loss.item()\r\n",
        "\r\n",
        "  optimizer.zero_grad()\r\n",
        "  loss.backward()\r\n",
        "  optimizer.step()\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    y_pred = model(X_test)\r\n",
        "    correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)\r\n",
        "    accuracy_list[epoch] = correct.mean()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 549.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.100443720817566\n",
            "1.0987790822982788\n",
            "1.0970916748046875\n",
            "1.0954004526138306\n",
            "1.0937223434448242\n",
            "1.092087745666504\n",
            "1.0904902219772339\n",
            "1.0889002084732056\n",
            "1.0873081684112549\n",
            "1.0856893062591553\n",
            "1.0840423107147217\n",
            "1.0823596715927124\n",
            "1.0806297063827515\n",
            "1.0788532495498657\n",
            "1.0770275592803955\n",
            "1.0751450061798096\n",
            "1.073196291923523\n",
            "1.0711694955825806\n",
            "1.0690906047821045\n",
            "1.0669734477996826\n",
            "1.0647889375686646\n",
            "1.0625247955322266\n",
            "1.0601798295974731\n",
            "1.0577505826950073\n",
            "1.0552202463150024\n",
            "1.052579402923584\n",
            "1.0498298406600952\n",
            "1.0469698905944824\n",
            "1.0439977645874023\n",
            "1.0409103631973267\n",
            "1.0377031564712524\n",
            "1.0343667268753052\n",
            "1.0308992862701416\n",
            "1.0272955894470215\n",
            "1.0235583782196045\n",
            "1.0196912288665771\n",
            "1.0157043933868408\n",
            "1.0115734338760376\n",
            "1.0073063373565674\n",
            "1.002903938293457\n",
            "0.9983848333358765\n",
            "0.9937433004379272\n",
            "0.9889920353889465\n",
            "0.9841557741165161\n",
            "0.9792455434799194\n",
            "0.9742565751075745\n",
            "0.9691999554634094\n",
            "0.9640847444534302\n",
            "0.958925187587738\n",
            "0.9537277221679688\n",
            "0.9484959840774536\n",
            "0.9432373046875\n",
            "0.9379712343215942\n",
            "0.9327064752578735\n",
            "0.9274587035179138\n",
            "0.9222445487976074\n",
            "0.9170835018157959\n",
            "0.911987841129303\n",
            "0.9069849848747253\n",
            "0.9020972847938538\n",
            "0.8973245024681091\n",
            "0.8926723003387451\n",
            "0.8881525993347168\n",
            "0.8837735652923584\n",
            "0.8795379996299744\n",
            "0.8754505515098572\n",
            "0.8715164661407471\n",
            "0.867734968662262\n",
            "0.8640990853309631\n",
            "0.8605989813804626\n",
            "0.8572290539741516\n",
            "0.853979229927063\n",
            "0.8508438467979431\n",
            "0.8478111624717712\n",
            "0.8448702692985535\n",
            "0.842010498046875\n",
            "0.8392255902290344\n",
            "0.8365150690078735\n",
            "0.8338668346405029\n",
            "0.8312708735466003\n",
            "0.8287262320518494\n",
            "0.8262297511100769\n",
            "0.8237619400024414\n",
            "0.8213136196136475\n",
            "0.8188892602920532\n",
            "0.8164846301078796\n",
            "0.814092218875885\n",
            "0.8116965889930725\n",
            "0.8093301653862\n",
            "0.806993842124939\n",
            "0.8046798706054688\n",
            "0.8023964762687683\n",
            "0.8001348972320557\n",
            "0.797903299331665\n",
            "0.7956912517547607\n",
            "0.793482780456543\n",
            "0.7912696599960327\n",
            "0.7890626192092896\n",
            "0.7868414521217346\n",
            "0.7846155762672424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}